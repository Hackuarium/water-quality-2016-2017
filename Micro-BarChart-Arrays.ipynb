{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot matrices of summer water quality testing\n",
    "\n",
    "1. Summer 2016 and 2017\n",
    "2. Joint project citizen science Hackuarium/hammerdirt\n",
    "\n",
    "### Usage:\n",
    "\n",
    "1. Graphics for citizen science article\n",
    "2. Output for web application\n",
    "3. You may use give us the credit\n",
    "\n",
    "### Contact and further information\n",
    "\n",
    "1. roger@hammerdirt.ch\n",
    "2. https://mwshovel.pythonanywhere.com/dirt/microbiology.html\n",
    "3. http://wiki.hackuarium.ch/w/Main_Page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re\n",
    "import seaborn\n",
    "import textwrap\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the 2017 data:\n",
    "\n",
    "#### We are working from the original csv\n",
    "\n",
    "We will need to do the following:\n",
    "\n",
    "1. Dates formatted\n",
    "2. Duplicates removed\n",
    "3. Errors corrected\n",
    "\n",
    "#### see the workbook \"Initial sorting and cat herding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('data/2017_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a duplicate value in the DF, the data was moved and then added as a record)\n",
    "# so we need to get rid of that:\n",
    "a.drop(12, inplace=True)\n",
    "# there is a column name that doesn't match the others\n",
    "a.rename(columns={'p3_fluo_halo_colonies':'P3_fluo_halo_colonies'}, inplace=True)\n",
    "# there is a sample number for a record where no samples weere taken, we need to fix that:\n",
    "a.loc[(a.Location == 'MRD') & (a.Date == '24.07.17'), \"Samples\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.loc[(a.Location == 'MRD') & (a.Date == '24.07.17')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = pd.read_csv('data/2017_Data/rain2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the categories/criteria for analysis/comparison\n",
    "\n",
    "1. Create labels for chart output\n",
    "2. Link column names to chart labels\n",
    "2. Create lists of unique values for categories/criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the unique dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(a.Date.unique())\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the locations of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = ['VNX', 'SVT',  'MRD']\n",
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the culture media:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediums = list(a['medium'].unique().copy())\n",
    "mediums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 24hour results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twentyFourHour = ['Date', 'Location', 'medium', 'Samples', 'Sampling_Notes', 'Water_temp', 'Plating_notes', 'Temp_incubation', 'P1_qty_sample', 'P1_fluo_halo_colonies', 'Plate_one_24h_image', 'P1_24h_big_blue', 'P1_24h_med_blue', 'P1_24h_green', 'P1_24h_turq', 'P1_24h_pink', 'P1_24h_other', 'Comments_p1_24h','P2_qty_sample','P2_fluo_halo_colonies', 'Plate_two_24h_image', 'P2_24h_big_blue', 'P2_24h_med_blue', 'P2_24h_green', 'P2_24h_turq', 'P2_24h_pink', 'P2_24h_other', 'Comments_p2_24h', 'P3_qty_sample', 'P3_fluo_halo_colonies', 'Plate_three_24h_image', 'P3_24h_big_blue', 'P3_24h_med_blue', 'P3_24h_green', 'P3_24h_turq', 'P3_24h_pink', 'P3_24h_other', 'Comments_p3_24h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twntyFor2017 = a[twentyFourHour]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 48hour results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fortyEightHour = ['Date','Location','medium','Samples','Sampling_Notes','Water_temp','Plating_notes','Temp_incubation','P1_qty_sample','P1_fluo_halo_colonies','Plate_one_48h_image','P1_48h_big_blue','P1_48h_med_blue','P1_48h_green','P1_48h_turq','P1_48h_pink','P1_48h_other','Comments_p1_48h','P2_qty_sample','P2_fluo_halo_colonies', 'Plate_two_48h_image','P2_48h_big_blue','P2_48h_med_blue','P2_48h_green', 'P2_48h_turq', 'P2_48h_pink','P2_48h_other','Comments_p2_48h','P3_qty_sample','P3_fluo_halo_colonies','Plate_three_48h_image','P3_48h_big_blue','P3_48h_med_blue', 'P3_48h_green','P3_48h_turq', 'P3_48h_pink','P3_48h_other', 'Comments_p3_48h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frtyEght2017 = a[fortyEightHour]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create week labels and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekLabels = ['Week one', 'Week two', 'Week three', 'Week four', 'Week five', 'Week six', 'Week seven', 'Week eight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the labels to the weeks\n",
    "# we will be comparing the weekly results from one year to the next\n",
    "# this will allow us to call results by week number\n",
    "weeksDates = dict(zip(weekLabels, dates))\n",
    "# inverse this relationship \n",
    "datesWeeks = {value:key for key, value in weeksDates.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: A dictionary that has the week number as key and the date of the sample as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeksDates[\"Week two\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create labels for colony colors\n",
    "\n",
    "1. Make a dictionary that ties column name to color\n",
    "2. Eliminate the plate reference\n",
    "3. Used to label charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create keys for charting labels\n",
    "platesColors = ['P1_fluo_halo_colonies','P1_48h_big_blue','P1_48h_med_blue','P1_48h_green','P1_48h_turq','P1_48h_pink','P1_48h_other','P2_fluo_halo_colonies', 'P2_48h_big_blue','P2_48h_med_blue','P2_48h_green', 'P2_48h_turq', 'P2_48h_pink','P2_48h_other','P3_fluo_halo_colonies','P3_48h_big_blue','P3_48h_med_blue', 'P3_48h_green','P3_48h_turq', 'P3_48h_pink','P3_48h_other','P1_fluo_halo_colonies','P1_24h_big_blue', 'P1_24h_med_blue', 'P1_24h_green', 'P1_24h_turq', 'P1_24h_pink', 'P1_24h_other','P2_fluo_halo_colonies','P2_24h_big_blue', 'P2_24h_med_blue', 'P2_24h_green', 'P2_24h_turq', 'P2_24h_pink', 'P2_24h_other','P3_fluo_halo_colonies','P3_24h_big_blue', 'P3_24h_med_blue', 'P3_24h_green', 'P3_24h_turq', 'P3_24h_pink', 'P3_24h_other']\n",
    "\n",
    "def makeKeys(a):\n",
    "    b = re.compile('fluo_halo', re.IGNORECASE)\n",
    "    c={}\n",
    "    for d,e in enumerate(a):\n",
    "        if b.search(a[d]):\n",
    "            f = 'UV Fluo'\n",
    "            g = {a[d]:f}\n",
    "            c.update(g)\n",
    "        else:\n",
    "            f = a[d][7:]\n",
    "            g = {a[d]:f}\n",
    "            c.update(g)\n",
    "    return c\n",
    "            \n",
    "platesColorsKeys = makeKeys(platesColors) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Feed the function a column name and it will return an abbreviated identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platesColorsKeys['P1_48h_med_blue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group plates by number and species\n",
    "\n",
    "1. We need to get the average of results from three different plates for the same species\n",
    "2. This needs to be iterable and indexable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group the plates by plate number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pOne48 = ['P1_fluo_halo_colonies','P1_48h_big_blue','P1_48h_med_blue','P1_48h_green',\n",
    "            'P1_48h_turq','P1_48h_pink','P1_48h_other']\n",
    "pTwo48= ['P2_fluo_halo_colonies','P2_48h_big_blue','P2_48h_med_blue',\n",
    "            'P2_48h_green','P2_48h_turq','P2_48h_pink','P2_48h_other']\n",
    "pThree48 = ['P3_fluo_halo_colonies','P3_48h_big_blue','P3_48h_med_blue',\n",
    "              'P3_48h_green','P3_48h_turq','P3_48h_pink','P3_48h_other']\n",
    "pOne24 = ['P1_fluo_halo_colonies', 'P1_24h_big_blue','P1_24h_med_blue',\n",
    "            'P1_24h_green', 'P1_24h_turq', 'P1_24h_pink', 'P1_24h_other']\n",
    "pTwo24 = ['P2_fluo_halo_colonies','P2_24h_big_blue','P2_24h_med_blue',\n",
    "            'P2_24h_green', 'P2_24h_turq', 'P2_24h_pink','P2_24h_other',]\n",
    "pThree24 = ['P3_fluo_halo_colonies', 'P3_24h_big_blue', 'P3_24h_med_blue',\n",
    "              'P3_24h_green', 'P3_24h_turq', 'P3_24h_pink','P3_24h_other']\n",
    "# Group the plates by incubation time\n",
    "platesFortyEight = [pOne48, pTwo48, pThree48]\n",
    "platesTwentyFour = [pOne24, pTwo24, pThree24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platesTwentyFour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group the species (color) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGroups(a):\n",
    "    b = np.arange(len(a[0]))\n",
    "    c=[]\n",
    "    for d in b:\n",
    "        e = []\n",
    "        for f in a:\n",
    "            e.append(f[d])\n",
    "        c.append(e)\n",
    "    return c\n",
    "fortyEightPlates = makeGroups(platesFortyEight)\n",
    "twentyFourPlates = makeGroups(platesTwentyFour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: the output should be all the plate counts for one color\n",
    "\n",
    "1. We use this to call the columns on a given day\n",
    "2. Then average the results for the three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twentyFourPlates[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for charting and JSON output\n",
    "\n",
    "1. Use the location list to select records from one location\n",
    "2. Use the mediums list to select results based on the growth medium used\n",
    "3. Use the weeks list to collect the results per growth medium per week\n",
    "4. Pass those results on to other functions that calculate and select specific values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit the dataframe to the location and culture medium desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that reduce the Data set to a specific location and medium\n",
    "# Returns a DataFrame where each row is a unique date\n",
    "\n",
    "def getLocation(df, places):\n",
    "    b = df[df.Location == places]\n",
    "    return b\n",
    "def getMedium(df, medium):\n",
    "    b = df[df.medium == medium]\n",
    "    return b\n",
    "def getWeeklyValues(df, week):\n",
    "    d = []\n",
    "    for a,b in enumerate(week):\n",
    "        c = df[df.Date == week[a]]\n",
    "        d.append(c)\n",
    "    return d\n",
    "# This function calls the other functions to produce the desired output\n",
    "# a list of dataframes, each dataFrame is one row of data that contains the values\n",
    "# for a specified day. location and culture medium\n",
    "def getItAll(df, places, medium, week):\n",
    "    a = getLocation(df, places)\n",
    "    c = getMedium(a, medium)\n",
    "    d = getWeeklyValues(c, week)\n",
    "    return d\n",
    "\n",
    "x = getItAll(a, locations[2], mediums[0], dates)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: call the variable \"x\" and give it an index number\n",
    "\n",
    "1. You can use column indexing by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just calling the columns that represent the sorting criteria\n",
    "# there are 72 columns in all\n",
    "# \"x\" will be passed on to the next set of functions\n",
    "x[6][[\"Date\", \"Location\", \"medium\",\"Sampling_Notes\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the results from the above functions and retrieve key information and perform calculations: \n",
    "\n",
    "1. Retrieve comments from sampling and counting\n",
    "2. Get the average color/day/location \n",
    "3. Identify \"Below detectable limit\" and \"Too many to count\"\n",
    "4. Put that all in a dictionary to be exported in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting comments:\n",
    "\n",
    "# The sampling comments are in one column\n",
    "# This information was entered by the person in the field who took the sample\n",
    "# If there are no samples \"Samples.values = 0\" then there should be a comment\n",
    "# If there are no samples and no comments we fill it in with \"Samples not taken\"\n",
    "# If there are samples then no comments would be registered\n",
    "\n",
    "def getSamplingComments(a):    \n",
    "    f = {}\n",
    "    for b in a:\n",
    "        c = b[\"Date\"].values[0]\n",
    "        d = b['Samples'].values[0]\n",
    "        if d == 0:\n",
    "            e = b[\"Sampling_Notes\"].item()\n",
    "            if e == \"No comments\":\n",
    "                no_t = 'Samples not taken'\n",
    "                f.update({d:no_t})\n",
    "            else:\n",
    "                no_t = e\n",
    "                f.update({c:no_t})                \n",
    "        else:\n",
    "            no_t = \"none\"\n",
    "            f.update({c:no_t})\n",
    "    return f\n",
    "\n",
    "# The count comments were provided by the person doing the colony counts\n",
    "# Specifically we wanted to know if the value was \"Too many to count\" -- tmtc\n",
    "# Therefore there is one comment block for each plate\n",
    "# We search each comment block for \"tmtc\"\n",
    "# if we find tmtc then the value is stored in a dictionary {Date:Comment}\n",
    "\n",
    "def getCountComments(a):\n",
    "    p = re.compile('tmtc', re.IGNORECASE)\n",
    "    countComments = ['Date','Location', 'Comments_p1_24h', 'Comments_p1_48h', 'Comments_p2_24h','Comments_p2_48h', 'Comments_p3_24h', 'Comments_p3_48h'] \n",
    "    b = {}\n",
    "    for a in x:\n",
    "        c = a[countComments]\n",
    "        e = c[\"Date\"].item()\n",
    "        f = {e:[]}\n",
    "        for d in countComments:           \n",
    "            if p.search(a[d].item()):                \n",
    "                g = c[d].item()\n",
    "                f[e].append(g)#               \n",
    "            else:\n",
    "                pass\n",
    "        b.update(f)\n",
    "    return b\n",
    "          \n",
    "          \n",
    "# The number of samples is noted in the dataframe\n",
    "# get the value and store it in a dictionary\n",
    "def getNumberOfSamples(a):\n",
    "    f = {}\n",
    "    for b in a:\n",
    "        c = b.Samples.item()\n",
    "        d = b.Date.item()\n",
    "        e = {d:c}\n",
    "        f.update(e)\n",
    "    return f\n",
    "\n",
    "# Get the average per color group, per day\n",
    "# Call the species groups ie.. fortyEightPlates\n",
    "# Iterate through the species groups\n",
    "# Averge the values greater than zero\n",
    "# Identify those values = zero and store in a dictionary \"Below detectable limit\"\n",
    "# Colors with BDL are given a nominal value of 1 (that way there will be a hint of color on the chart)\n",
    "# Store all results in a dicitionary where the keys are the unique dates\n",
    "\n",
    "def getAverage(plates,data):\n",
    "    c = np.arange(len(plates))\n",
    "    d = np.arange(len(data))\n",
    "    e = {0.5:200, 1:100, 4:25}\n",
    "    f = {}\n",
    "    for g in d:\n",
    "        h = data[g][\"Date\"].item()\n",
    "        i = data[g]['P1_qty_sample'].item()\n",
    "        r = data[g][\"Location\"].item()\n",
    "        j = e[i]\n",
    "        k = {h:{}}\n",
    "        o = {\"BDL\":[]}\n",
    "        s = {\"Qty plated\":i}\n",
    "        aves = {\"Averages\":[]}\n",
    "        for l in c:\n",
    "            m = data[g][plates[l]].mean(axis=1).item()\n",
    "            p = platesColorsKeys[plates[l][0]]\n",
    "            ave = m*j            \n",
    "            if ave == 0:\n",
    "                o[\"BDL\"].append(p)\n",
    "                ave += 1\n",
    "            aves[\"Averages\"].append(ave)        \n",
    "        k[h].update(aves)\n",
    "        k[h].update(o)\n",
    "        k[h].update(s)\n",
    "        f.update(k)\n",
    "    q = {r:f}\n",
    "    return q\n",
    "\n",
    "# A function for converting the dates to week numbers\n",
    "def dateToWeek(a):\n",
    "    f = {}\n",
    "    for b,c in a.items():\n",
    "        d = datesWeeks[b]\n",
    "        e = {d:c}\n",
    "        f.update(e)\n",
    "    return f  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Plating comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theComs = getSamplingComments(x)\n",
    "theComs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Counting comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countingComments = getCountComments(x)\n",
    "countingComments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfSamples = getNumberOfSamples(x)\n",
    "numberOfSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Daily averages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theResults = getAverage(fortyEightPlates, x)\n",
    "theResults['MRD']['12.06.17']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "1. Combine all the results for each location and sample day\n",
    "2. Use a dictionary format where the key is location\n",
    "3. Create bar-chart array\n",
    "4. Export to JSON create Web output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all the results and iterate through the locations\n",
    "\n",
    "1. Create one dictionary per culture medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllLocations(df, places, medium, dates):\n",
    "    a = {}\n",
    "    b = np.arange(len(places))\n",
    "    for c in b:\n",
    "        d = getItAll(df, places[c], medium, dates)\n",
    "        e = {places[c]:d}\n",
    "        a.update(e)\n",
    "    return a\n",
    "allResults = getAllLocations(a, locations, mediums[0], dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOutput(data, places, plates):\n",
    "    f = {}\n",
    "    for i,n in enumerate(places):\n",
    "        a = data[n]\n",
    "        b = getAverage(plates, a)\n",
    "        c = getSamplingComments(a)\n",
    "        d = getCountComments(a)\n",
    "        e = getNumberOfSamples(a)\n",
    "        g = list(b[n].keys())\n",
    "        for date  in g:\n",
    "            b[n][date].update({\"Sample Comments\":c[date]})\n",
    "            b[n][date].update({\"Count Comments\":d[date]})\n",
    "            b[n][date].update({\"Number of Samples\":e[date]})          \n",
    "            \n",
    "        f.update(b)\n",
    "    return f\n",
    "theOutput = makeOutput(allResults, locations,twentyFourPlates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theOutput[\"SVT\"] \n",
    "\n",
    "##  2017 Create a graph that displays the average colony counts per day & location \n",
    "# 1. Identify and note \"Below detectable limit\"\n",
    "# 2. Create a matrix Row = sample day, column = location\n",
    "# 3. Note the days and locations samples were not taken\n",
    "# 4. Make output SVG for web applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# start the function\n",
    "def plot_ez_totals(x, bars, svgtitle, pngtitle, title, subtitle, colors, legendColors):\n",
    "    # number of rows depends on the number of weeks\n",
    "    rows = len(dates)\n",
    "    # the number of columns depends on the number of locations\n",
    "    cols = len(x)\n",
    "    # this is the number of bars in each chart\n",
    "    # this depends on the number of color groups\n",
    "    ind = np.arange(bars)#<--- this can be made a variable\n",
    "    # the width of each bar\n",
    "    # width one means there is no space between bars\n",
    "    width = 1\n",
    "    # assign appropriate colors per grop\n",
    "    # note the index number of each color matches the index number of the values from the first fucntion\n",
    "    colss = colors\n",
    "    # set up the figure and the array of charts\n",
    "    f, axar = plt.subplots(rows, cols, figsize=(12,24), sharey='row')\n",
    "    # create some space in between the rows for x axis labels, and titles\n",
    "    f.subplots_adjust(hspace=0.6, wspace=0.1)\n",
    "    # run through the results generated by the previous fucntion\n",
    "    for i in np.arange(cols):\n",
    "        a = i\n",
    "        b = locations[a]\n",
    "        c = x[b]\n",
    "        d = datesWeeks[dates[a]]\n",
    "        for n,day in enumerate(dates):\n",
    "            if i == 0:\n",
    "                if c[day]['Sample Comments'] != \"none\":\n",
    "                    axar[n, i].text(0.05, 10, c[day]['Sample Comments'], fontsize=10)\n",
    "                    axar[n, i].set_title(b)\n",
    "                    axar[n, i].set_ylabel(\"Colony forming units per 100mL\", fontdict={'fontsize': 7, 'fontweight': 'medium'},\n",
    "                                      labelpad=1,)\n",
    "                    axar[n, i].xaxis.set_major_locator(plt.NullLocator())\n",
    "                    axar[n, i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "                else:\n",
    "                    axar[n, i].bar(ind, c[day][\"Averages\"], width, color=colss)\n",
    "                    axar[n, i].set_ylim(0, max(c[day][\"Averages\"]) + 50)\n",
    "                    axar[n, i].set_title(b + ': ' +  day + ', samples: ' + str(c[day]['Number of Samples']) + ', ' +\n",
    "                                     str(c[day]['Qty plated'])+ 'mL', fontdict={'fontsize': 10, 'fontweight': 'medium'})\n",
    "                    labels =  \", \".join(c[day][\"BDL\"])\n",
    "                    axis_label = textwrap.fill(labels, width=30)\n",
    "                    #axar[n, i].set_xlabel('BDL : '+ str(axis_label))\n",
    "                    axar[n, i].set_ylabel(\"Colony forming units per 100mL\", fontdict={'fontsize': 7, 'fontweight': 'medium'},\n",
    "                                      labelpad=1,)\n",
    "                    axar[n, i].xaxis.set_major_locator(plt.NullLocator())\n",
    "                    axar[n, i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "            else:\n",
    "                if c[day]['Sample Comments'] != \"none\":\n",
    "                    axar[n, i].text(0.05, 10, c[day]['Sample Comments'], fontsize=10)\n",
    "                    axar[n, i].set_title(b)\n",
    "                    axar[n, i].xaxis.set_major_locator(plt.NullLocator())\n",
    "                    axar[n, i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "                else:\n",
    "                    axar[n, i].bar(ind, c[day][\"Averages\"], width, color=colss)\n",
    "                    axar[n, i].set_ylim(0, max(c[day][\"Averages\"]) + 50)\n",
    "                    axar[n, i].set_title(b + ': ' +  day + ', samples: ' + str(c[day]['Number of Samples']) + ', ' +\n",
    "                                     str(c[day]['Qty plated'])+ 'mL', fontdict={'fontsize': 10, 'fontweight': 'medium'})\n",
    "                    labels =  \", \".join(c[day][\"BDL\"])\n",
    "                    axis_label = textwrap.fill(labels, width=30)\n",
    "                    #axar[n, i].set_xlabel('BDL : '+ str(axis_label))                    \n",
    "                    axar[n, i].xaxis.set_major_locator(plt.NullLocator())\n",
    "                    axar[n, i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "                \n",
    "    \n",
    "    plt.annotate(title, xy=(0.5, .98),  xycoords=\"figure fraction\",                 \n",
    "                 size=18, ha='center', va=\"top\")\n",
    "    plt.annotate(subtitle, xy=(0.5, .96),  xycoords=\"figure fraction\",                 \n",
    "                 size=12, ha='center', va=\"top\")\n",
    "   \n",
    "    def makePatches(colors, legendColors):\n",
    "        a = []\n",
    "        for i,b in enumerate(colors):\n",
    "            c = mpatches.Patch(color=colors[i], label=legendColors[i])\n",
    "            a.append(c)\n",
    "        return a\n",
    "        \n",
    "    plt.legend(handles=makePatches(colors, legendColors),bbox_to_anchor=(0.11,.87, .8, .08),\n",
    "               mode=\"expand\",loc=\"center\", ncol=len(colors), bbox_transform=f.transFigure )\n",
    "    plt.savefig(svgtitle)\n",
    "    plt.savefig(pngtitle)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the variables for the charting function\n",
    "\n",
    "1. Correlate species to color\n",
    "2. Identify the colors you are going to use\n",
    "3. Make a title\n",
    "4. Make a subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speciesColor = ['E.coli UV-fluo','E.coli','Other coliforms', 'Salmonella','Salmonella','Aeromonas','other',]\n",
    "speciesColor = ['Bioindicator UV+','Bioindicator','Other coliforms', 'Salmonella', 'EnterobactX','Aeromonas','other',]\n",
    "\n",
    "colors =       ['darkviolet',      'darkblue',    'dodgerblue',      'green',      'turquoise', 'pink',     'lightslategray']\n",
    "title = \"Average 24 hour colony counts June-July 2017: ECA Check Plus UV\"\n",
    "subTitle = \"MRD = Montreux marché, SVT = Sauvetage, VNX = Vernex, BDL = Below detectable limit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the chart function with the defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ez_totals(theOutput, 7, \"data/charts/2017_BARCHART_ARRAY.svg\", \"data/charts/2017_BARCHART_ARRAY.png\", title, subTitle, colors, speciesColor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust for 2016 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data:\n",
    "\n",
    "#### This data has already been transformed\n",
    "\n",
    "1. Dates formatted\n",
    "2. Duplicates removed\n",
    "3. Errors corrected\n",
    "\n",
    "#### see the workbook \"Initial sorting and cat herding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv('data/2016_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the categories/cirteria for analysis/comparison\n",
    "\n",
    "1. Create labels for chart output\n",
    "2. Link column names to chart labels\n",
    "2. Create lists of unique values for categories/criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the unique dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates16 = list(c.Date.unique())\n",
    "dates16.sort()\n",
    "dates16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the locations of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the culture mediums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium16 = ['easy_gel']\n",
    "medium16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 24hour results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twntyFor2016 = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 48hour results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create week labels and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeksDates16 = dict(zip(weekLabels, dates16))\n",
    "# inverse this relationship \n",
    "datesWeeks16 = {value:key for key, value in weeksDates16.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create labels for colony colors\n",
    "\n",
    "1. Make a dictionary that ties column name to color\n",
    "2. Eliminate the plate reference\n",
    "3. Used to label charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platesColors16 = ['P1_24h_big_blue', 'P1_24h_med_blue','P1_24h_other', 'P1_24h_pink', 'P1_24h_turq', 'P1_qty_sample',\n",
    "                  'P2_24h_big_blue', 'P2_24h_med_blue', 'P2_24h_other', 'P2_24h_pink','P2_24h_turq', 'P3_24h_big_blue', 'P3_24h_med_blue', 'P3_24h_other',\n",
    "                  'P3_24h_pink', 'P3_24h_turq']\n",
    "platesColorsKeys16 = makeKeys(platesColors16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platesColorsKeys16['P1_24h_other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Group plates by number and species\n",
    "\n",
    "1. We need to get the average of results from three different plates for the same species\n",
    "2. This needs to be iterable and indexable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group the plates by plate number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pOne24 = ['P1_24h_big_blue', 'P1_24h_med_blue', 'P1_24h_turq', 'P1_24h_pink', 'P1_24h_other']\n",
    "pTwo24 = ['P2_24h_big_blue', 'P2_24h_med_blue', 'P2_24h_turq', 'P2_24h_pink', 'P2_24h_other']\n",
    "pThree24 = ['P3_24h_big_blue', 'P3_24h_med_blue', 'P3_24h_turq', 'P3_24h_pink', 'P3_24h_other']\n",
    "platesTwentyFour16 = [pOne24, pTwo24, pThree24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group the species(color) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twentyFourPlates16 = makeGroups(platesTwentyFour16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: the output should be all the plate counts for one color\n",
    "\n",
    "1. We use this to call the columns on a given day\n",
    "2. Then average the results for the three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twentyFourPlates16[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limit the dataframe to the location and culture medium desired\n",
    "\n",
    "1. 2016 data has only one culture medium - \"easy-gel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that reduce the Data set to a specific location \n",
    "# Returns a DataFrame where each row is a unique date\n",
    "\n",
    "def getLocation(df, places):\n",
    "    b = df[df.Location == places]\n",
    "    return b\n",
    "def getWeeklyValues(df, week):\n",
    "    d = []\n",
    "    for a,b in enumerate(week):\n",
    "        c = df[df.Date == week[a]]\n",
    "        d.append(c)\n",
    "    return d\n",
    "# This function calls the other functions to produce the desired output\n",
    "# a list of dataframes, each dataFrame is one row of data that contains the values\n",
    "# for a specified day. location and culture medium\n",
    "def getItAll16(df, places, week):\n",
    "    a = getLocation(df, places)\n",
    "    d = getWeeklyValues(a, week)\n",
    "    return d\n",
    "\n",
    "x16 = getItAll16(c, locations[2], dates16)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are just calling the columns that represent the sorting criteria\n",
    "# there are 72 columns in all\n",
    "# \"x\" will be passed on to the next set of functions\n",
    "x16[1][[\"Date\", \"Location\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the results from the above functions and retrieve key information and perform calculations: \n",
    "\n",
    "1. ~~Retrieve comments from sampling and counting~~\n",
    "2. Get the average color/day/location \n",
    "3. Identify \"Below detectable limit\" and \"Too many to count\"\n",
    "4. Put that all in a dictionary to be exported in JSON format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In 2016 there were three samples per sampleday\n",
    "# get the value and store it in a dictionary\n",
    "def getNumberOfSamples16(a):\n",
    "    f = {}\n",
    "    for b in a:\n",
    "        c = 3\n",
    "        d = b.Date.item()\n",
    "        e = {d:c}\n",
    "        f.update(e)\n",
    "    return f\n",
    "\n",
    "# Get the average per color group, per day\n",
    "# Call the species groups ie.. fortyEightPlates\n",
    "# Iterate through the species groups\n",
    "# Averge the values greater than zero\n",
    "# Identify those values = zero and store in a dictionary \"Below detecable limit\"\n",
    "# Colors with BDL are given a nominal value of 1 (that way there will be a hint of color on the chart)\n",
    "# Store all results in a dicitionary where the keys are the unique dates\n",
    "\n",
    "def getAverage(plates,data):\n",
    "    c = np.arange(len(plates))\n",
    "    d = np.arange(len(data))\n",
    "    e = {0.4: 250, 0.5:200, 1:100, 4:25}\n",
    "    f = {}\n",
    "    for g in d:\n",
    "        h = data[g][\"Date\"].item()\n",
    "        i = data[g]['P1_qty_sample'].item()\n",
    "        r = data[g][\"Location\"].item()\n",
    "        j = e[i]\n",
    "        k = {h:{}}\n",
    "        o = {\"BDL\":[]}\n",
    "        s = {\"Qty plated\":i}\n",
    "        aves = {\"Averages\":[]}\n",
    "        for l in c:\n",
    "            m = data[g][plates[l]].mean(axis=1).item()\n",
    "            p = platesColorsKeys[plates[l][0]]\n",
    "            ave = m*j            \n",
    "            if ave == 0:\n",
    "                o[\"BDL\"].append(p)\n",
    "                ave += 1\n",
    "            aves[\"Averages\"].append(ave)         \n",
    "        k[h].update(aves)\n",
    "        k[h].update(o)\n",
    "        k[h].update(s)\n",
    "        f.update(k)\n",
    "    q = {r:f}\n",
    "    return q\n",
    "\n",
    "# A function for converting the dates to week numbers\n",
    "def dateToWeek(a):\n",
    "    f = {}\n",
    "    for b,c in a.items():\n",
    "        d = datesWeeks[b]\n",
    "        e = {d:c}\n",
    "        f.update(e)\n",
    "    return f  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfSamples16 = getNumberOfSamples16(x16)\n",
    "numberOfSamples16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Daily averages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theResults16 = getAverage(platesTwentyFour16 , x16)\n",
    "theResults16['MRD']['2016-06-28']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "1. Combine all the results for each location and sample day\n",
    "2. Use a dictionary format where the key is location\n",
    "3. Create bar-chart array\n",
    "4. Export to JSON create Web output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine all the results and iterate through the locations\n",
    "\n",
    "1. Create one dictionary per culture medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllLocations16(df, places, dates):\n",
    "    a = {}\n",
    "    b = np.arange(len(places))\n",
    "    for c in b:\n",
    "        d = getItAll16(df, places[c], dates)\n",
    "        e = {places[c]:d}\n",
    "        a.update(e)\n",
    "    return a\n",
    "allResults16 = getAllLocations16(c, locations, dates16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOutput16(data, places, plates):\n",
    "    f = {}\n",
    "    for i,n in enumerate(places):\n",
    "        a = data[n]\n",
    "        b = getAverage(plates, a)\n",
    "        e = getNumberOfSamples16(a)\n",
    "        g = list(b[n].keys())\n",
    "        for date  in g:\n",
    "            b[n][date].update({\"Number of Samples\":e[date]})           \n",
    "        f.update(b)\n",
    "    return f\n",
    "theOutput16 = makeOutput16(allResults16, locations,twentyFourPlates16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theOutput16[\"MRD\"]['2016-06-21']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016   Create a graph that displays the average colony counts per day & location \n",
    "1. Identify and note \"Below detectable limit\"\n",
    "2. Create a matrix Row = sample day, column = location\n",
    "3. Note the days and locations samples were not taken\n",
    "4. Make output SVG for web applications\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# start the function\n",
    "def plot_ez_totals16(x, bars, svgtitle, pngtitle, title, subtitle, colors, legendColors):\n",
    "    # number of rows depends on the number of weeks\n",
    "    rows = len(dates16)\n",
    "    # the number of columns depends on the number of locations\n",
    "    cols = len(x)\n",
    "    # this is the number of bars in each chart\n",
    "    # this depends on the number of color groups\n",
    "    ind = np.arange(bars)#<--- this can be made a variable\n",
    "    # the width of each bar\n",
    "    # width one means there is no space between bars\n",
    "    width = 1\n",
    "    # assign appropriate colors per grop\n",
    "    # note the index number of each color matches the index number of the values from the first fucntion\n",
    "    colss = colors\n",
    "    # set up the figure and the array of charts\n",
    "    f, axar = plt.subplots(rows, cols, figsize=(12,24), sharey='row')\n",
    "    # create some space in between the rows for x axis labels, and titles\n",
    "    f.subplots_adjust(hspace=0.6, wspace=0.1)\n",
    "    # run through the results generated by the previous fucntion\n",
    "    for i in np.arange(cols):\n",
    "        a = i\n",
    "        b = locations[a]\n",
    "        c = x[b]\n",
    "        d = datesWeeks16[dates16[a]]\n",
    "        for n,day in enumerate(dates16):\n",
    "            if i == 0:\n",
    "                axar[n, i].bar(ind, c[day][\"Averages\"], width, color=colss)\n",
    "                axar[n, i].set_ylim(0, max(c[day][\"Averages\"]) + 50)\n",
    "                axar[n, i].set_title(b + ': ' +  day + ', samples: ' + str(c[day]['Number of Samples']) + ', ' +\n",
    "                                 str(c[day]['Qty plated'])+ 'mL', fontdict={'fontsize': 10, 'fontweight': 'medium'})\n",
    "                labels =  \", \".join(c[day][\"BDL\"])\n",
    "                axis_label = textwrap.fill(labels, width=30)\n",
    "                axar[n, i].set_ylabel(\"Colony forming units per 100mL\", fontdict={'fontsize': 7, 'fontweight': 'medium'},\n",
    "                                      labelpad=1,)\n",
    "                #axar[n, i].set_xlabel('BDL : '+ str(axis_label))\n",
    "                axar[n, i].xaxis.set_major_locator(plt.NullLocator())\n",
    "                axar[n, i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "            else:\n",
    "                axar[n, i].bar(ind, c[day][\"Averages\"], width, color=colss)\n",
    "                mx = max(c[day][\"Averages\"])\n",
    "                print(f\"{n},{day}, max = {mx}\")\n",
    "                axar[n, i].set_ylim(0, max(c[day][\"Averages\"]) + 50)\n",
    "                axar[n, i].set_title(b + ': ' +  day + ', samples: ' + str(c[day]['Number of Samples']) + ', ' +\n",
    "                                 str(c[day]['Qty plated'])+ 'mL', fontdict={'fontsize': 10, 'fontweight': 'medium'})\n",
    "                labels =  \", \".join(c[day][\"BDL\"])\n",
    "                axis_label = textwrap.fill(labels, width=30)\n",
    "                #axar[n, i].set_xlabel('BDL : '+ str(axis_label))\n",
    "                axar[n, i].xaxis.set_major_locator(plt.NullLocator())\n",
    "                axar[n, i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    \n",
    "    plt.annotate(title, xy=(0.5, .98),  xycoords=\"figure fraction\",                 \n",
    "                 size=18, ha='center', va=\"top\")\n",
    "    plt.annotate(subtitle, xy=(0.5, .96),  xycoords=\"figure fraction\",                 \n",
    "                 size=12, ha='center', va=\"top\")\n",
    "   \n",
    "    def makePatches(colors, legendColors):\n",
    "        a = []\n",
    "        for i,b in enumerate(colors):\n",
    "            c = mpatches.Patch(color=colors[i], label=legendColors[i])\n",
    "            a.append(c)\n",
    "        return a\n",
    "        \n",
    "    plt.legend(handles=makePatches(colors, legendColors),bbox_to_anchor=(0.11,.87, .8, .08),\n",
    "               mode=\"expand\",loc=\"center\", ncol=len(colors), bbox_transform=f.transFigure )\n",
    "    plt.savefig(svgtitle)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the variables for the charting function\n",
    "\n",
    "1. Correlate species to color\n",
    "2. Identify the colors you are going to use\n",
    "3. Make a title\n",
    "4. Make a subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speciesColor16 = ['Bioindicator','Other coliforms', 'Salmonella','Aeromonas','other',]\n",
    "colors16 = ['darkblue', 'dodgerblue', 'turquoise', 'pink', 'lightslategray']\n",
    "title16 = \"Average 24 hour colony counts June-August 2016: ECA Check\"\n",
    "subTitle16 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ez_totals16(theOutput16, 5, \"data/charts/2016_BARCHART_ARRAY.svg\", \"new2016.png\", title16, subTitle16, colors16, speciesColor16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theOutput16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json(a, b):\n",
    "    with open(a, 'wb') as f:\n",
    "        f.write(json.dumps(b).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_json(\"data/JSON/APP_OUTPUT/barchartsArrays2017.json\", theOutput)\n",
    "make_json(\"data/JSON/APP_OUTPUT/barchartsArrays2016.json\",theOutput16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
